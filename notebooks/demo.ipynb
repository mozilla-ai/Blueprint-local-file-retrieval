{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local File Retrieval Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use the Local File Retrieval application to:\n",
    "\n",
    "- Load and process documents (including PDFs).\n",
    "- Create embeddings using a configurable model.\n",
    "- Store embeddings in a SQLite vector database.\n",
    "- Perform similarity searches with a configurable `k` value.\n",
    "- Interactively query the database.\n",
    "\n",
    "Feel free to modify the code and configurations to suit your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization and Experimentation\n",
    "\n",
    "- **Change the Query:** Modify the `query_text` variable to test different queries.\n",
    "- **Adjust 'k' Value:** Change the value of `k` in the configuration cell to retrieve more or fewer results.\n",
    "- **Use a Different Embedding Model:** Update `model_name` to use a different SentenceTransformer model.\n",
    "- **Add More Data:** Place additional documents (including PDFs) in the your data directory and rerun the notebook.\n",
    "- **Modify Chunk Size and Overlap:** Adjust `chunk_size` and `chunk_overlap` in the configuration cell to see how it affects the results.\n",
    "- **Explore the Code:** Feel free to delve into the source code in the `src/` directory to understand how each component works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import application modules\n",
    "from src import data_loader, embedding, database, query\n",
    "import yaml\n",
    "import sqlite3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the folder path where your documents are located\n",
    "folder_path = \"../data/example_data\"  # adjust as needed\n",
    "\n",
    "# Define the SQLite database file to use\n",
    "db_file = \"../documents.db\"  \n",
    "\n",
    "# specify the model name to use for creating embeddings\n",
    "model_name = \"all-MiniLM-L6-v2\" #visit HuggingFace models for other model ideas\n",
    "\n",
    "# Define chunk size and overlap for document splitting\n",
    "chunk_size = 1000  #number of characters per chunk\n",
    "chunk_overlap = 100  # number of characters to overlap between chunks\n",
    "\n",
    "# Define the file extensions to consider when loading documents - so you can ignore certain files\n",
    "file_extensions = [\".txt\", \".md\", \".py\", \".json\", \".csv\", \".pdf\"]\n",
    "\n",
    "# Specify the number of top similar documents to retrieve for each query\n",
    "k = 5  # number of top similar documents to return\n",
    "\n",
    "# Display the configurations\n",
    "print(f\"Folder Path: {folder_path}\")\n",
    "print(f\"Database File: {db_file}\")\n",
    "print(f\"Embedding Model: {model_name}\")\n",
    "print(f\"Chunk Size: {chunk_size}\")\n",
    "print(f\"Chunk Overlap: {chunk_overlap}\")\n",
    "print(f\"File Extensions: {file_extensions}\")\n",
    "print(f\"Number of Results to Retrieve (k): {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "print(\"Loading documents...\")\n",
    "documents = data_loader.load_documents(os.path.abspath(os.path.join('..', folder_path)), file_extensions)\n",
    "if not documents:\n",
    "    print(\"No valid documents found in the specified folder.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(documents)} documents.\")\n",
    "\n",
    "# Split documents into chunks\n",
    "print(\"Splitting documents into chunks...\")\n",
    "docs = data_loader.split_documents(documents, chunk_size, chunk_overlap)\n",
    "print(f\"Split into {len(docs)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding model\n",
    "print(f\"Initializing embedding model: {model_name}\")\n",
    "model = embedding.initialize_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings\n",
    "print(\"Creating embeddings...\")\n",
    "contents, sources, embeddings = embedding.create_embeddings(model, docs)\n",
    "print(f\"Created embeddings for {len(embeddings)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database setup and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database\n",
    "print(\"Initializing database...\")\n",
    "db_path = os.path.abspath(os.path.join('..', db_file))\n",
    "db = database.initialize_database(db_path, embedding_dim=embeddings[0].shape[0])\n",
    "\n",
    "# Insert data into database\n",
    "print(\"Inserting data into database...\")\n",
    "database.insert_data(db, contents, sources, embeddings)\n",
    "print(\"Data insertion complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing your similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "query_text = \"Enter your query here\"  # Replace with your query or use input()\n",
    "\n",
    "# Perform similarity search\n",
    "print(f\"Performing similarity search for: '{query_text}'\")\n",
    "results = query.query_database(db, model, query_text, k=k)\n",
    "\n",
    "# Display results\n",
    "if results:\n",
    "    for idx, result in enumerate(results, start=1):\n",
    "        doc_id, distance, content, source = result\n",
    "        print(f\"\\nResult {idx}:\")\n",
    "        print(f\"Source: {source}\")\n",
    "        print(f\"Similarity Score: {distance}\")\n",
    "        print(f\"Content Snippet:\\n{content[:500]}\")\n",
    "        print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"No relevant documents found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "db.close()\n",
    "print(\"Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
